
<a id="markdown-1-进程" name="1-进程"></a>
# 1. 进程

1. “现代操作系统”：一个进程就是一个**正在执行**程序的实例。
2. 知乎用户： 进程就是上下文切换之间程序执行的部分，是**运行中**程序的描述，也是对应于**该段 CPU 执行时间的描述**。 [线程和进程的区别是什么？ - zhonyong的回答 - 知乎](https://www.zhihu.com/question/25532384/answer/81152571)

由此，可以看出 **动态性** 是进程最基本的特性。

<!-- TOC -->

- [1. 进程](#1-进程)
  - [1.1. 概述](#11-概述)
  - [1.2. 进程的状态](#12-进程的状态)
  - [1.3. 进程控制块](#13-进程控制块)
  - [进程实体（进程 image）](#进程实体进程-image)
  - [1.4. 创建进程](#14-创建进程)
    - [创建一个新进程的过程](#创建一个新进程的过程)
  - [1.5. 终止进程](#15-终止进程)
    - [进程终止的过程](#进程终止的过程)
  - [进程切换](#进程切换)
  - [1.6. 线程](#16-线程)
    - [1.6.1. 线程和进程](#161-线程和进程)
  - [1.7. 进程之间的通信](#17-进程之间的通信)
    - [1.7.1. 竞争条件（race condition）](#171-竞争条件race-condition)
    - [1.7.2. 临界区（critical section）](#172-临界区critical-section)
    - [1.7.3. 互斥方案](#173-互斥方案)
      - [1.7.3.1. 屏蔽中断](#1731-屏蔽中断)
      - [1.7.3.2. 锁变量](#1732-锁变量)
      - [1.7.3.3. 严格轮换法（单标志法）](#1733-严格轮换法单标志法)
      - [1.7.3.4. Peterson 解法](#1734-peterson-解法)
      - [1.7.3.5. TSL 指令](#1735-tsl-指令)
      - [1.7.3.6. 睡眠和唤醒](#1736-睡眠和唤醒)
      - [1.7.3.7. 生产者-消费者问题](#1737-生产者-消费者问题)
      - [1.7.3.8. 信号量](#1738-信号量)
        - [1.7.3.8.1. 用信号量解决生产者-消费者问题](#17381-用信号量解决生产者-消费者问题)
        - [1.7.3.8.2. 互斥量](#17382-互斥量)
      - [1.7.3.9. 管程](#1739-管程)
        - [1.7.3.9.1. 条件变量](#17391-条件变量)
        - [1.7.3.9.2. 管程和信号量的局限性](#17392-管程和信号量的局限性)
      - [1.7.3.10. 消息传递](#17310-消息传递)
        - [1.7.3.10.1. 消息传递解决生产者-消费者问题](#173101-消息传递解决生产者-消费者问题)
      - [1.7.3.11. 屏障](#17311-屏障)

<!-- /TOC -->


<a id="markdown-11-概述" name="11-概述"></a>
## 1.1. 概述

由于 CPU 资源和其他计算机资源的速度不协调，为了提高资源利用率，提出了多任务系统。由于 CPU 的计算速度，即使对于单 CPU 而言，此时的多任务系统也是宏观“并行”的，即并发的。然而这种并发在临界资源访问时就会出现问题，即产生竞争条件。[1.7. 进程之间的通信](#17-进程之间的通信) 会具体介绍。具体表现为，进程 A 和 B 并发执行，都可以访问共享变量 `cnt` 并进行加 1 操作。对于某个时刻 A 先取的其值为 a，然而在 a 还未 更改为 a+1 之前，B 也取得其值为 a，而不是期望中的 a+1。

任务的执行需要依赖各个 PC 资源，称之为计算机执行的 **上下文**，要实现这种“并行”，就需要不断切换上下文，此时便产生了进程概念，用来描述这种程序当前上下文的状态信息。这种上下文的概念再缩小一点，如对整个上下文的某个子集，进行切换，则代价会小的多，这种情况下，线程的概念就产生了。

进程就是对正在运行程序的一种抽象，进程中使用的虚拟化技术之一，即 CPU 虚拟化，支持并发能力，将单独的 CPU 资源，虚拟为多个 CPU 资源。每个进程都拥有一个虚拟 CPU。 更一般的，计算机中所有可运行的程序（包括操作系统）都是被组织成若干进程。

对于段页式和页式存储而言，进程所包含的地址空间是使用 **页表** 实现的。每个进程都有一个独有的地址空间，这涉及到 **内存虚拟化**。页表将虚拟地址映射为物理地址。

每个进程都有一个页表，这样每个进程就都有自己独立的地址空间了。用户内存空间和内核空间如图所示，内核的指令和数据也会被进程映射到进程的地址空间内。当进程使用系统调用时，系统调用实际上会在进程地址空间中的内核区域执行。这种设计使得内核的系统调用代码可以直接指向用户内存。

这在 C 中就可以使用结构体 `struct proc` 来定义一个进程的状态，该状态中包含进程的页表、内核栈、当前运行的状态（如寄存器上下文）等。一个进程包括以下的上下文资源分类如下。

上下文：

1. 用户级上下文：代码，数据，堆栈，文件，等等
2. 寄存器上下文：各类寄存器，以及栈指针 ESP 
3. 系统级上下文：进程控制块、内存管理信息、内核栈

1和2是用户内存空间，3只对内核可见，是表示进程的状态等信息。

切换上下文：
先保存当前程序 A 的上下文，然后调入下一个程序 B 的上下文，然后执行 B，B 中断，保存 B 的上下文，在加载先前保存的 A 的上下文。

~~~
由此可见，进程是资源分配的基本单位。
~~~

进程中有一个 **运行线程**，或简称为线程，来执行进程的指令。线程可以被挂起，稍后再恢复运行。进程的切换实际上就是挂起当前运行的线程，恢复另一个进程的线程（即上面提到的上下文的切换）。线程的状态，如局部变量、函数调用的返回地址等保存在线程的栈上。

如前所述，进程有 **用户栈** 和 **内核栈**。当进程运行用户指令时，只有用户栈被使用，内核栈为空。当进程通过系统调用或中断进入内核态，内核代码在进程中的内核栈中执行；进程处于内核中时，其用户栈仍然保存着数据，只是暂时处于不活跃的状态。进程的线程交替使用着用户栈和内核栈。


<a id="markdown-12-进程的状态" name="12-进程的状态"></a>
## 1.2. 进程的状态

1. 运行态： 正在运行的进程，拥有 CPU 资源
    - 单处理器，只有一个进程处于运行态
    - 多处理器，可以有多个进程处于运行态
2. 就绪态：
    - 可运行，但是因为其他进程正在运行而**暂时**停止
    - 等待被调度
    - 获得 CPU 以外的所有必要资源，只要再获得 CPU 资源，便可立即执行
3. 阻塞态：
    - 当某个进程不能继续进行，如等待用户的输入，用户不输入则该进程不能继续进行，等待资源

![](image/2.png)

各个进程之间的转换由**进程调度程序**负责运行态和就绪态的转换。调度程序有自己的调度机制。

每个进程都是一个独立的实体，有其自己的程序计算器和其他状态信息，进程之间经常需要相互作用。一个进程的输出可以是零个进程的输入。如 Shell 命令

``` shell
cat t1 t2 t3 | grep tree
```

第一个进程执行 `cat` ，将三个文件连接并输出；第二个进程执行 `grep` 。根绝这两个进程的相对速度，可能发生： `grep` 准备就绪可以运行，但输入未完成，此时必须阻塞 `grep` ，直到输入到来。


<a id="markdown-13-进程控制块" name="13-进程控制块"></a>
## 1.3. 进程控制块

Process control block（PCB），描述进程的基本信息和运行状态，所谓的创建进程和撤销进程都是对 PCB 操作。进程表的一个表项对应一个进程，一个表项大致为

|    PCB item     |
| :-------------: |
|     寄存器      |
|   程序计数器    |
|    堆栈指针     |
|    进程状态     |
|     优先级      |
|    调度参数     |
|   进程ID(pid)   |
|     父进程      |
|     进程组      |
|      信号       |
|  进程开始时间   |
|  使用的CPU时间  |
| 子进程的CPU时间 |

> PCB 是进程存在的唯一标志！


<a id="markdown-进程实体进程-image" name="进程实体进程-image"></a>
## 进程实体（进程 image）

一个进程 image（进程实体）由下面三部分构成

1. 程序段
2. 数据段
3. PCB


<a id="markdown-14-创建进程" name="14-创建进程"></a>
## 1.4. 创建进程

创建进程的主要场景有：

* 系统初始化：操作系统的运行也是由进程构成的，启动操作系统会创建许多进程，包括负责前端部分和后台部分。
* 执行了正在运行的进程所调用的进程创建系统调用：如进程创建子进程
* 用户请求创建一个新的进程
* 一个批处理作业的初始化：略过

创建新进程的系统调用 `fork` 。 `fork` 创建的进程称为**子进程**， `fork` 调用会创建一个和调用进程相同的副本，即不同的地址空间，其内容相同。这两个副本中，彼此是独立的，即进程 A 在其地址空间中修改一个字，其子进程不受此影响。当然，其中不可写的内存区是共享的。

随后，子进程执行 `execve` 修改其地址空间并运行一个新的程序。

而进程和它所有的子进程以及子进程的子进程等共同组成了一个**进程组**。如 Shell 中键入 `sort` ，此时 Shell 将会创建一个子进程用来执行 `sort` 。 每个进程有一个 `pid` （process identifier）， `fork` 函数返回就是一个整数。（注：查看所有进程的命令为 `ps` ）


<a id="markdown-创建一个新进程的过程" name="创建一个新进程的过程"></a>
### 创建一个新进程的过程

1. 为新进程分配一个唯一的标识号，申请一个空白的 PCB，若 PCB 申请失败，则创建失败
2. 为进程分配资源，如内存空间。若资源不足，则处于阻塞态
3. 初始化 PCB
4. 若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待调度


<a id="markdown-15-终止进程" name="15-终止进程"></a>
## 1.5. 终止进程

进程被终止的场景：

* 正常退出（完成工作）：此时通知操作系统，然后调用 `exit` ，终止进程
* 出错退出：出现异常
* 严重错误：进程发现了严重错误，如 `gcc foo.c` ，编译程序 `foo.c` ，但是该文件不存在
* 被其他进程杀死：系统调用 `kill` 。

系统调用是 `exit` 。


<a id="markdown-进程终止的过程" name="进程终止的过程"></a>
### 进程终止的过程

1. 根据被终止进程的标识符，检索 PCB，从中读出该进程的状态
2. 若被终止进程处于执行态，立即终止该进程的执行，将 CPU 分配给其他进程
3. 若该进程还有子孙进程，则终止所有的子孙进程
4. 将该进程拥有的所有资源归还给父进程或 OS
5. 将该 PCB 从所有链表（队列）中删除


<a id="markdown-进程切换" name="进程切换"></a>
## 进程切换

切换进程实质上就是切换上下文。具体过程如下，

1. 保存 CPU 上下文
2. 更新 PCB 信息
3. 把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列
4. 选择另一个进程，并更新其 PCB
5. 。。。
6. 恢复 CPU 上下文


<a id="markdown-16-线程" name="16-线程"></a>
## 1.6. 线程

线程是独立调度的基本单位。为什么在进程的基础又抽象出线程的概念？

一个进程中的线程共享进程资源（即进程的上下文）。例如，浏览器进程可以有许多线程，负责 HTTP 请求的线程、事件相应的线程、渲染线程等等。


<a id="markdown-161-线程和进程" name="161-线程和进程"></a>
### 1.6.1. 线程和进程

1. [线程和进程的区别是什么？ - biaodianfu的回答 - 知乎](https://www.zhihu.com/question/25532384/answer/411179772) ：该回答将进程类比于火车，线程类比于车厢。
2. [线程和进程的区别是什么？ - zhonyong的回答 - 知乎](https://www.zhihu.com/question/25532384/answer/81152571) ：该回答提到进程和线程出现的背景，
    - 进程是上下文切换之间程序执行的部分，是运行中程序的描述，也是对应于该段 CPU 执行时间的描述
    - 进程粒度太大，切换进程（主要为三个上下文）所需要的开销太大

例子：
实现程序 A，分成 a, b, c 三块组合而成，这里的执行就可能变成：程序 A 得到 CPU ---> CPU 加载上下文 ---> 开始执行 A 的 a 部分，然后执行 A 的 b 部分，接着 c 部分，最后 CPU 保存 A 的上下文。

:exclamation: 这里的 a, b, c 的执行共享了 A 的上下文， CPU 在执行的时候没有上下文切换的（时间是更小粒度的上下文切换，如只切换了寄存器上下文）。**这里的 a, b, c 就是线程**，也就是说线程是共享了进程的上下文环境的更为细小的 CPU 时间段。

线程共享进程分配的资源，这意味着线程的修改会影响同一进程的其他线程，如一个程序中的全局变量，先被 a 模块修改，很显然 b 模块使用这个变量的时候，已经是修改后的值。

线程也有三种状态，类似于进程，管理线程的也是一个**线程表**，记录线程的信息，如寄存器上下文程序计数器，寄存器，堆栈，状态等。


<a id="markdown-17-进程之间的通信" name="17-进程之间的通信"></a>
## 1.7. 进程之间的通信

进程之间通信有三类高级通信【PV 操作为低级通信】：

1. 共享内存
    - 进程内的线程是共享进程空间的
    - 不同进程的空间是相互独立的
    - 共享内存的相互通信需要系统调用来实现
2. 消息传递
    - 以 Message 为单位，一种格式换的数据信息
    - 当无法通过共享内存来通信时，由 OS 提供的消息传递方法
    - 通过 send 和 receive 原语进行数据交换

``` 

消息传递：

1. 直接通信
2. 间接通信
    - 发送进程发送到中间某个实体，称之为 『信箱』

```

3. 管道通信
    - 用于连接一个读进程和一个写进程的一个共享文件，又名 `pipe` 文件。
    - 向 `pipe` 以字符流形式将大量的数据送入管道
    - 接收进程从管道中读数据
    - 提供：互斥、同步和确定对方存在的能力

> 管道是一种特殊的文件
> 管道是一种特殊的共享存储的优化和发展

如 Linux 下的 Shell 管道命令

``` shell
cat a b c | grep t
```

第一个进程的输出必须传送给第二个进程。进程之间的通信需要解决三个问题：

1. 如何传递信息？
2. 如何解决资源竞争？-互斥
3. 如何解决顺序？-同步


<a id="markdown-171-竞争条件race-condition" name="171-竞争条件race-condition"></a>
### 1.7.1. 竞争条件（race condition）

公用存储区，如一个共享文件，有多个进程可以访问。这种情况下，考虑一个例子。当一个进程需要打印一个文件时，它将文件名放在一个特殊的 spooler directory 下，另一个进程（打印机守护进程）则周期性检查是否有文件需要打印。若有则打印并将该文件名从目录下删除。

假设该目录有许多槽位，编号为 0，1，2，...，每个槽位存放一个文件名。同时假设有两个共享变量：out，指向下一个要打印的文件；in，指向目录中下一个空闲槽位。某一时刻，0\~3 号槽位空，4\~6 号槽位被占用。几乎同一时刻，进程 A 和 B 都决定将一个文件排队打印。

此时，可能发生以下情况：A 读取 in 的值为 7，将 7 存在一个局部变量 next_free_slot 中。此时，**发生了一次时钟中断**，CPU 认为 A 已经运行了足够长的时间，决定切换到 B。B 也读取到 in，同样得到值 7，于是将 7 存在 B 的局部变量 next_free_slot 中。此时，两个进程都认为下一个可用槽位为 7。

进程 B 现在继续运行，将其文件名存在槽位 7 中并将 in 的值更新为 8，然后离开。A 接着上次中断的地方继续运行，它检查变量 next_free_slot，发现其值为 7，于是将打印名存在 7 号槽位，这样就把 B 之前存的文件名覆盖掉。然后将 next_free_slot 加 1，得到 8，将 8 存到 in 中。此时，打印机守护进程可能发现不了任何错误，但进程 B 永远得不到任何打印输出。

这种情况，即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称之为**竞争条件**。


<a id="markdown-172-临界区critical-section" name="172-临界区critical-section"></a>
### 1.7.2. 临界区（critical section）

如何避免竞争条件？实际上，凡涉及共享资源的情况都会引发类似错误，要避免这种错误，关键是要找出某种方法来阻止多个进程同时读写共享资源。即，需要**互斥（mutual exclusion）**。

避免竞争条件的问题也可以使用一种抽象的方式描述。一个进程的一部分时间做内部计算或不会引发竞争条件的操作。在某些时候，进程可能需要访问共享资源，或执行一些会导致竞争的操作。我们把共享资源进行访问的**程序片段**称为临界区（critical section）。如果我们能够适当地安排，使得两个进程不能同时处于临界区中，就能够避免竞争条件。

使用临界区的互斥机制：A 进入临界区，B 试图进入，但是失败。随后 B 被暂时挂起直到 A 离开临界区，从而允许 B 立即进入。

为了禁止两个进程同时进入临界区，同步/互斥机制应遵循以下原则。

1. 空闲让进
2. 忙则等待
3. 有限等待
4. 让权等待


<a id="markdown-173-互斥方案" name="173-互斥方案"></a>
### 1.7.3. 互斥方案


<a id="markdown-1731-屏蔽中断" name="1731-屏蔽中断"></a>
#### 1.7.3.1. 屏蔽中断

即一个进程进入临界区后立即屏蔽所有中断，并在就要离开之前打开中断。屏蔽中断后，时钟中断也被屏蔽。**CPU 只有发生时钟中断或其他中断时才会进行进程切换**，这样屏蔽之后 CPU 将不会切换到其他进程。

这种方案很容易看到非常不好：

* 对于多处理器系统，屏蔽中断仅对 disable 指令的那个 CPU 有效 （随后介绍的 TSL 指令便可以解决这一点）
* 中断交给用户进程十分危险，如忘了再打开中断，系统可能由此崩溃终止 
* 浪费 CPU 资源 （硬件上实现真正的互斥必须要屏蔽中断或使用更进一步的 TSL 指令，锁住内存总线，阻止进程切换）


<a id="markdown-1732-锁变量" name="1732-锁变量"></a>
#### 1.7.3.2. 锁变量

软件加锁，即有一个共享变量（锁），初始值为 0，表示可以进入临界区。为 1 表示不可以。

但是这种方法，容易和先前例子中一样的错误。假设一个进程读取到锁变量的值发现其为 0，而恰好在其值设置为 1 之前，另一个进程被调度运行，将该锁变量设置为 1。当第一个进程再次能运行时，它同样将锁设为 1，则此时同时有两个进程进入了临界区。


<a id="markdown-1733-严格轮换法单标志法" name="1733-严格轮换法单标志法"></a>
#### 1.7.3.3. 严格轮换法（单标志法）

> https://blog.csdn.net/qq_41587740/article/details/108854852

该方法如下，有一个变量 `turn` ，初始值为 0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。具体机制如下：进程 A 检查 `turn` ，发现其值为 0，于是进入临界区。进程 B 发现其值为0，所以在一个等待循环中，不停测试 `turn` ，看其值何时变为 1。连续测试直到某个值（即轮到进程 B 的对应的值，如 1）出现为止。这种称为**忙等待**：即进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。
```c++

// 进程 A 
while (TRUE) {

    while (turn != 0) ;
    critical_region();
    // 进程 A 退出临界区后，将其值设为 1
    turn = 1;
    noncritical_region();
}

// 进程 B
while (TRUE) {

    while (turn != 1) ;
    critical_region();
    // 进程 B 退出临界区，将其设为 0
    turn = 0;
    noncritical_region();
}
``` 

从这里，可以体会为什么该方法称之为严格轮换法。因为必须按照 `Process A -> Process B -> Process A -> ...` 的过程进行。比如某时刻的 `turn = 0`，即表示该『轮到』进程 A 进入临界区。但是 A 不想进入临界区，从而没法将 `turn` 设置为 1，即没法『轮到』进程 B 进入临界区。从而违背了『空闲让进』的原则，造成资源浪费。

或者考虑现代操作系统中给出的一个复杂例子，如可以考虑当进程 A 进程比 B 快得多时，该机制的问题：进程 A 离开临界区，将 `turn` 值设为 1，以便允许进程 B 进入临界区。假设 B 很快执行完临界区的操作，离开临界区，此时两个进程都处于临界区之外（但还在该 `while(TRUE)` 循环内）， `turn` 的值又被设为 0。现在进程 A 很快执行完整个循环，然后又进入临界区，随着退出临界区，将 `turn` 的值设为 1。此时 `turn` 的值为 1，两个进程都处于临界区外执行（B 还未执行到 `turn=0` 这个语句时。）。

此时，进程 A 结束了非临界区的操作，并返回到 `while (TRUE)` 循环开始。此时， A 不能进入临界区，因为此时 `turn` 的值还是 1（B 还未执行到更改 `turn` 值的语句），而此时进程 B 还在忙于非临界区的操作，进程 A 只有继续 `while(turn != 0)` 循环，直到进程 B 将 `turn` 值改为 0。这说明，在一个进程比另一个慢的多的情况下，轮流进入临界区并不是一个好办法。

此时就产生了问题：临界区外的进程（如上例中的 B 处于临界区外时），阻塞了 B 进入临界区。

这种忙等待的锁，称为**自旋锁（spin lock）**。该机制可表述为
```c++
while(抢锁(lock)==没抢到){}
```

只要没有锁上，就不断重试。显然，如果别的进程长期持有该锁或离开临界区后没有解锁，那么进程就要一直测试是否能够加锁，浪费 CPU 资源。


<a id="markdown-1734-peterson-解法" name="1734-peterson-解法"></a>
#### 1.7.3.4. Peterson 解法

1981 年，G. L. Peterson 提出一种简单的互斥算法。如下
```c++
#define N 2             // 进程数量
int turn; 
int interested[N]; 

void enter_regeion(int process){

    int other;
    other = 1 - process;
    interested[process] = TRUE;
    turn = process;
    while(turn == process && interested[other] == TRUE){}   // 空语句，忙等待

}

void leave_region(int process){

    interested[process] = FALSE;

}

``` 

> 该算法的思想，即每个进程访问临界区资源之前，先检查临界资源是否正在被访问，若正在被访问，则等待；否则进入临界区。

该方法使用共享变量（即进入其临界区）之前，各个进程调用 `enter_region` 。其中 `while(turn == process && interested[other] == TRUE){}` 表示该调用在需要时使该进程等待。离开临界区后，调用 `leave_region` 。

一开始，没有任何进程进入临界区，即 `interested[]` 都为 `FALSE` 。由于进程 O 调用 `enter_region` 时，进程 1 并不想进入临界区，所以 `enter_region` 很快就会返回。如果进程 1 现在调用 `enter_region` ，进程 1 将在此处挂起直到 `interested[0]` 变成 `FALSE` ,该事件只有在进程 0 调用 `leave_region` 退出临界区时才会发生。

现在考虑两个进程几乎同时调用 `enter_region` 的情况。它们都将自己的进程号存入 `turn` ，但只有后被保存进去的进程号才有效，前一个因此被重写而丢失。假设进程 1 是后入的，则 `turn` 为 1。当两个进程都运行 `while` 语句时，进程 0 将循环 0 次并进入临界区，而进程 1 则将不停循环且不能进入临界区，直到进程 0 退出临界区为止。

> 真巧妙的解法！ 尤其是 `while` 循环中 `turn == process` 的判断。正好解决了上面说的问题。


<a id="markdown-1735-tsl-指令" name="1735-tsl-指令"></a>
#### 1.7.3.5. TSL 指令

```asm
TSL RX,LOCK       | 将 lock 读到寄存器 RX 中，然后在该内存地址上存入一个非零值
```

上面的指令称为**测试并加锁（test and set lock）**。该指令的读字和写字是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。**执行 TSL 指令的 CPU 将锁住内存总线，以禁止其他 CPU 在本指令结束之前访问内存**。

由此可见，锁住内存总线和屏蔽中断并不等同。屏蔽中断，不能阻止总线上的其他处理器在读操作和写操作**之间**访问该内存字。事实上，CPU1 屏蔽中断对 CPU2 没有任何影响。然后两者隔离开的**唯一办法**，即锁住总线，这需要一个特殊的硬件设施。

使用 TSL 指令则很简单，假设通过共享变量 `lock` 来协调对共享内存的访问。当 `lock` 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程用一条 `move` 指令将 `lock` 的值重新设置为 0。（这里一定要记住 TSL 指令可以保证进程的互斥访问）

使用 TSL 防止两个进程同时进入临界区的方案就很简单了，如下：

``` asm
enter_region:
    TSL REGISTER,LOCK       | 复制锁到寄存器并将锁设为 1
    CMP REGISTER,#0         
    JNE enter_region
    RET
leave_region:
    MOVE LOCK,#0
    RET
```

进程进入临界区之前先调用 `enter_region`，这将导致忙等待，直到锁空闲为止。这与之后介绍的 [1.7.3.8.2. 互斥量](#17382-互斥量)也是通过 TSL 指令实现的，即将 `mutex` 信号量替换成这里的 `lock`，不过也有其他不同之处。

> 简单来看，TSL 指令的效果比屏蔽中断更强一点，毕竟不同处理器也被限制了。因此可以从硬件上确保一个进程使用 TSL 指令的期间没有其他进程访问共享字段，从而实现互斥进入临界区。


<a id="markdown-1736-睡眠和唤醒" name="1736-睡眠和唤醒"></a>
#### 1.7.3.6. 睡眠和唤醒

`sleep` 和 `wakeup` 是进程通信间的原语，在无法进入临界区时阻塞，而不是忙等待。下面用生产者消费者问题来说明 `sleep` 和 `wakeup` 的用法。


<a id="markdown-1737-生产者-消费者问题" name="1737-生产者-消费者问题"></a>
#### 1.7.3.7. 生产者-消费者问题

producer-consumer 问题，又称有界缓冲区问题（bounded-buffer）。两个进程共享一个固定大小的缓冲区。其中一个为生产者，将信息放入 buffer 中，另个是消费者，从缓冲区取出信息。

问题在于当缓冲区已满，而此时生产者还想再放入一个新的数据项的情况。解决方法是让生产者睡眠，待 buffer 不满时再唤醒它。当消费者试图从 buffer 中取出时，若 buffer 为空，消费者则睡眠，直到生产者向 buffer 中放入数据后再将其唤醒。

这个方法依然会产生先前叙述的竞争条件（打印机的例子）。生产者消费者代码如下，
```c++
#define N 100   // buffer 中的糟个数
int count = 0; // buffer 中的数据项数目

void producer(void){

    int item;
    while(TRUE){
        item = produce_item();
        if(count == N) sleep();     // 如果 buffer 满了，则进入休眠状态
        insert_item(item);          
        count = count + 1;
        if(count == 1) wakeup(consumer);    
    }

}

void consumer(void){

    int item;
    while(TRUE){
        if(count == 0) sleep(); 
        item = remove_item();
        count = count - 1;
        if(count == N - 1) wakeup(producer);
        consume_item(item);         
    }

}

``` 

其中的 `count` 就属于一个共享变量，有可能出现以下竞争条件。buffer 为空，消费者刚刚读取的 `count` 值发现为 0。此时，调度程序将消费者暂停，启动运行生产者。生产者向 buffer 中加入一个数据项， `count` 加 1。此时， `count` 变成了 1。它推断由于 `count` 刚才为 0，所以消费者一定在睡眠，于是生产者唤醒消费者。

但是，**消费者此时在逻辑上并未睡眠**（即此时不一定处于这样一种状态，即消费者不一定进行消费，然后发现 buffer 为空，继而调用 `sleep` ），所以 `wakeup` 信号丢失。当消费者下次运行时，它将测试先前读取的 `count` 值，发现它为 0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程将永远睡眠下去。

问题的实质在于，发给一个（尚）未睡眠的进程的 `wakeup` 信号丢失了。一个简单的补丁可以是，加上一个**唤醒等待位**。当一个 `wakeup` 信号，发送给一个清醒的进程信号时，将该位置置为 1。随后，该进程要睡眠时，如果唤醒等待为位 1，则将该位清除，而该进程仍然保持清醒。唤醒等待位实际上就是 `wakeup` 信号的一个小仓库。

然而，如果有多个进程，那么一个唤醒等待为就不够用了，于是继续加补丁，加入更多唤醒等待位。该方法没有从根本上解决问题。


<a id="markdown-1738-信号量" name="1738-信号量"></a>
#### 1.7.3.8. 信号量

> 信号量由 E. W. Dijikstra 于 1965 年提出的一种方法，使用一个整形变量来累计唤醒次数。在他的建议下，引入了一个新的变量类型，称作**信号量（semaphore）**。Dijikstra 建议设立两种操作：down 和 up（分别为一般化后的 `sleep` 和 `wakeup` ，有的资料记为 `wait(S)` 和 `signal(S)` ）。Dijkstra 论文中，分别使用 P 和 V 而不是 down 和 up，荷兰语中 Proberen 的意思是尝试，Verhogen 的含义是增加或升高。因此，“现代操作系统”一书中使用 down 和 up 代替 PV 操作。其中 PV 操作都是原语。

知乎用户给出一个例子介绍互斥锁和信号量的概念。即信号量 S 就是一个停车场。当前值是停车场里还剩下多少个空车位。最大值是停车场里最多能容纳多少个车位。当汽车进入停车场时，首先要在门口排队(sem_wait)，得到进入许可后才能进入。排队顺序原则上先到先得（也可以是其它规则）。每进一辆车，停车场就少了 1 个停车位，即信号量当前值减 1。当前值为 0 时，停车场停满了，所有车不得进入统统在门口排队等。当一辆车离开后，释放其所占据的停车位(sem_post)，信号量当前值 +1 信号量值得到释放后，如果门口有正在排队的车，那么就放进来，每放进来一个就重复前面的步骤。

"现代操作系统"中说，一个信号量 S 的取值可以为 0 或为正值，且信号量会有一个初值（大于 0），不过为了方便和便于理解，采用以下说法，即信号量是一个整数：

* 为非负数时，代表可供并发进程使用的资源实体数，即临界区的并发数，车库的最大值为临界区最大的并发数
* 为负数时，代表 sem_wait 队列中的，等待使用临界区的进程数

对一信号量，执行 down 操作：

1. 检查其值是否大于 0，若大于 0，则将其值减一，表示用掉一个保存的唤醒信号（即，用掉一个车位），并继续执行该进程。
2. 若该值为 0，则将该进程睡眠（阻塞该进程，即上面对应的车库中车位已经满了），而且此时 down 操作并未结束，转入进程调度程序。

> 原子操作，即一组相关联的操作，要不都不间断的（不被打断）地执行，要么都不执行。

对一信号量执行 up 操作：

1. 信号量的值加 1。
2. 若相加后的值大于 0，说明等待队列中没有进程等待唤醒，所以进程可以继续执行。
3. 若相加后的值小于等于 0，说明有进程在等待队列中，则从该信号的等待队列中（sem_wait）中唤醒一个等待进程，然后再返回原进程继续执行（此时已经离开临界区了）或转进程调度。

注：原书中“如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个（如随机挑选）并允许该进程完成它的 down 操作”这句话就是指有进程在等待队列 sem_wait 中。原书中"于是，对一个有进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍然为 0，但在该信号量上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如前面的模型中不会有进程因执行 `wakeup` 而阻塞一样"，这表明原书中的信号量不取负数。

1. 整型信号量
PV 操作必须成对使用，PV 原语执行期间不允许有中断的发生。因此，PV 操作可以描述为
```c++
wait(S){
    while (S <= 0){}
    S = S - 1;
}// P 操作
signal(S){
    S = S + 1;
}// V 操作
```

由于 PV 操作都是原语，因此不会出现之前那样的竞争条件。信号量可以协调进程对共享资源的访问。任一时刻只能有一个执行线程进入临界区（多个进程并发访问临界区？）。

> 注意到，该方法依然违背“让权等待”原则，即 `wait` 操作中的 `while (S <= 0)` 会不断的尝试，占据 CPU 资源，从而使进程处于“忙等”状态。

2. 记录型信号量

对于简单的 PV 操作，当 `while (S <=0)` 时，我们可以让该进程阻塞，并挂在等待队列中。从而就解决了“让权等待”问题。

```c++
wait(semaphore S){
    S.value--;
    if (S.value < 0){
        add this process to S.L;
        block(S.L);
    }
}

signal(semaphore S){
    S.value++;
    if (S.value <=0){
        remove a process P from S.L;
        wakeup(P);
    }
}

```



运作方式：

1. Init，给定信号量 S 一个非负数，表示最大的并发数，即车库的最大容量。
2. 企图进入临界区的进程，执行 P 操作，当 S 减为负数时，进程则进入等待队列。当不为负数时，进入临界区。
3. 结束离开临界区的资源，将会执行 V 操作。当 S 不为负数时，则。。。

reference: 

1. [如何理解互斥锁和信号量，以及他们在系统编程中是如何配合使用的？ - Chen Moore的回答 - 知乎](https://www.zhihu.com/question/40562993/answer/87204567)
2. [wikipedia-信号量](https://zh.wikipedia.org/wiki/%E4%BF%A1%E5%8F%B7%E9%87%8F)
3. [百度百科-信号量机制](https://baike.baidu.com/item/%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6)
4. [简书-信号量机制分类](https://www.jianshu.com/p/93128a6cb0f0)


<a id="markdown-17381-用信号量解决生产者-消费者问题" name="17381-用信号量解决生产者-消费者问题"></a>
##### 1.7.3.8.1. 用信号量解决生产者-消费者问题

用信号量可以解决之前提到的 `wakeup` 丢失的问题。为了确保信号量可以正确工作，最重要的是采用原子操作。

> 保证原子操作最直接的方式即，在执行某个操作时，暂时屏蔽中断。

操作只需在以下操作时暂时屏蔽全部中断：

* 测试信号量
* 更新信号量
* 在需要时，使某个进程睡眠

由于这几个操作只需要几条指令，所以此时的屏蔽中断的副作用很小。如果使用多个 CPU，则每个信号量应由一个锁变量进行保护。通过 TSL 或 XCHG 指令来确保同一时刻只有一个 CPU 在对信号量进行操作。

应当注意，使用 TSL 或 XCHG 指令来防止几个 CPU 同时访问一个信号量，这与 生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量的操作仅需几个毫秒，而生产者或消费者则可能需要任意长的时间。

下面是使用信号量解决生产者-消费者问题的代码示意：
```c++
#define N 100               // buffer 中的槽数目
using semaphore = int ; // int 表示信号量类型
semaphore mutex = 1; // 控制对临界区的访问
semaphore empty = N; // 计数 buffer 中的空槽数目
semaphore full = 0; // 信号量中的满槽数目

void producer(void){

    int item;
    while(TRUE){
        item = producer_item();
        down(&empty);       // 空槽数目 -1
        down(&mutex);       // 进入临界区
        insert_item(item);  // 插入数据项到 buffer 中
        up(&mutex);         // 离开临界区
        up(&full);          // 满槽的数目 +1
    }

}

void consumer(void){

    int item;
    while(TRUE){
        down(&full);
        down(&mutex);           // 进入临界区
        item = remove_item();   
        up(&mutex);             // 离开临界区
        up(&empty);
        consumer_item(item);    // 处理数据项
    }

}

``` 

其中， `mutex` 用于互斥，它用于保证任一时刻只有一个进程读写 buffer 和相关的变量。 `full` 记录充满的槽数目，初值为 0； `empty` 记录空的缓冲槽的总数，初值为 `N` 。 `mutex` 初值为 1，保证只有一个进程可以进入临界区，这种称为**二元信号量（binary semaphore）**。

> 个人看法：信号量解决生产者-消费者问题的核心，在于 PV 操作是原子操作。如果原始生产者-消费者解决方法中的 `count` 变量的访问和后续的操作，这一连串的操作整体也是原子操作，那么依然不会出现之前 `wakeup` 信号丢失的问题。然而，这样的原子操作显然比 PV 操作的代价高的多。

信号量的另一个用途是用于实现**同步（synchronization）**。信号量 `full` 和 `empty` 用来保证某种事件的顺序发生或不发生。后续再介绍如何用信号量实现同步。


<a id="markdown-17382-互斥量" name="17382-互斥量"></a>
##### 1.7.3.8.2. 互斥量

> 如果不需要信号量的计数能力，可以使用信号量的一个简化版本，即**互斥量（mutex）**，或称为互斥信号量。互斥量仅仅适用于管理共享资源或一小段代码。互斥量实现既容易又有效，这使得互斥量在实现用户空间线程包时非常有用。

互斥量处于两种状态之一的变量：解锁状态、加锁状态。一般用整形变量表示，0 表示解锁，非 0 表示加锁。

互斥量使用：当一个线程（或进程）需要访问临界区，它调用 `mutex_lock` 。如果该互斥量当前是解锁的（即互斥量为 0，表示临界区可用），此调用成功，该线程（进程）可以自由进入该临界区。

如果该互斥量已经加锁，调用线程（进程）被阻塞，直到在临界区中的线程完成并调用 `mutex_unlock` 。如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁（或按照其他规则）。

互斥量的汇编代码如下：
```asm
mutex_lock:
    TSL REGISTER,MUTEX      | 将互斥信号量复制到寄存器，并将其置为1
    CMP REGISTER,#0         | 互斥量为 0？
    JZE ok                  | 如果互斥量为 0，则被解锁，所以返回
    CALL thread_yield       | 互斥信号量忙，调度另一个线程
    JMP mutex_lock          | 稍后再试
ok: RET                     | 返回调用者；进入临界区

mutex_unlock:
    MOVE MUTEX,#0           | 将 mutex 置为 0
    RET                     | 返回调用者
```

这里的代码和 TSL 指令一节介绍的 `enter_region` 代码很相似（见[1.7.3.5. TSL 指令](#1735-tsl-指令)），关键区别在于：当 `enter_region` 进入临界区失败时，它将忙等待。实际上，由于时钟超时的作用，会调度其他进程运行。这样迟早拥有锁的进程会进入运行并释放锁。

然而，在（用户）线程中，没有时钟超时的作用。结果就是忙等待的方式会将试图获得锁的线程永远循环下去，绝不会得到锁。因为这个运行的线程不会让其他线程运行从而释放锁。

以上就是 `mutex_lock` 和 `enter_region` 的差别所在。后者取锁失败后，它调用 `thread_yield` 将 CPU 放弃给另一个线程。这样，就没有忙等待。在该线程下次运行时，再一次检查是否可以获得锁。


<a id="markdown-1739-管程" name="1739-管程"></a>
#### 1.7.3.9. 管程

引入管程的原因：由于先前的信号量和互斥量在编写的时候易出错，如 PV 操作的顺序如果不慎重考虑，将会造成**死锁（dead lock）**。例如， `mutex` 的值在 `empty` 之前而不是之后被 -1。如果 buffer 完全满了，生产者被阻塞， `mutex` 为 0。这样一来，当消费者下次试图访问缓冲区时，它将对 `mutex` 执行一个 P 操作，由于 `mutex` 值为 0，则消费者也将阻塞。两个进程都将永远地阻塞下去，无法再进行有效的工作，这种状态就是死锁。

使用信号量的时候，需要非常小心。为了更易于编写正确的程序，Brinch Hansen 和 Hoare 提出了一种高级同步原语，称为**管程（monitor）**。管程是一个由过程、变量和数据结构等组成的一个集合，它们组成了一个特殊的模块或软件包。管程的定义如下（需要明确的是 C 不支持管程，以下代码只为示意）。Provide by [作者：钓雪](https://www.zhihu.com/question/30641734/answer/105402533)
```c++
#define MAX 100
monitor PC{

    int count = 0; 
    /* 我们使用条件变量full 表示被填满的buffer, empty 表示空的buffer */
    conditon full, empty;
    void insert(int item){
        /* 当buffer满的时候,我们在full上将插入操作阻塞 */
        if ( count == MAX ) wait(&full);
        insert_item(item);
        count += 1;
        /* 当buffer不空的时候,我们在empty上唤醒取出操作 */
        if ( count == MAX -1 ) signal(&empty);    
    }

    int remove(){
        /* 当buffer空的时候,我们在empty上将取出操作阻塞 */
        if( count == 0 ) wait(&empty);
        remove_item(item);
        count -= 1;
        /* 当buffer不满的时候,我们在full上唤醒插入操作 */
        return item;
        if( count == MAX - 1) signal(&full);
    }

}

    void producer(){
        int item;
        item = produce_item();
        /*调用管程中的函数 */
        PC.insert(item);
    }
    
    void consumer(){
        int item;
        /*调用管程中的函数 */
        item = PC.remove();
        consumer_item();
    }

``` 

这里先不用关心管程的具体定义，只需要知道管程保证同一时刻只有一个进程在管程内活动，即管程内定义的操作在同一时刻只被一个进程调用（由编译器实现）。但是这样并不能保证进程以设计的顺序执行，因此需要设置条件变量，让进入管程而无法继续执行的进程阻塞自己。管程是编程语言的组成部分，编译器知道它们的特殊性。因此可以采用与其他过程调用不同的方法来处理对管程的调用。典型的处理方法是，当一个进程调用管程过程时，该过程中的前几条指令将检查在管程中是否有其他活跃进程。如果有，调用进程将被挂起，直到另一个进程离开管程将其唤醒。如果没有活跃进程在使用管程，则该调用进程可以进入。

:exclamation:进入管程时的互斥由编译器负责，通常的做法是使用一个互斥量或二元信号量。因为是编译器而非程序员安排互斥，所以出错的可能性要小得多。在任一时刻，写管程的人无须关心编译器是如何实现互斥的。只需直到将所有的临界区转换为管程过程即可，绝不会有两个进程同时执行临界区的代码。

现在管程还需要一种办法使得进程在无法继续运行的时候被阻塞，在生产者-消费者问题中，很容易针对对缓冲区满和缓冲区空的测试放到管程过程中，但是生产者在发现缓冲区满的时候如何阻塞呢？


<a id="markdown-17391-条件变量" name="17391-条件变量"></a>
##### 1.7.3.9.1. 条件变量

解决办法即，引入**条件变量**（condition variable）以及相关的两个操作：wait 和 signal。当一个管程过程发现它无法继续运行时（如，生产者发现缓冲区满），它会在某个条件变量上（如 `full` ）执行 wait 操作。该操作导致调用进程自身阻塞。并且还将另一个以前等在管程之外的进程调入管程。

另一个进程，比如消费者，可以唤醒正在睡眠的伙伴进程，这可以通过对其伙伴正在等待的一个条件变量执行 signal 完成。为了避免管程中同时有两个活跃进程，我们需要一条规则来通知在 signal 之后该怎么办。该规则可以为：执行 signal 的进程必须立即退出管程，即 signal 语句只能作为一个管程过程中的最后一条语句。如果一个条件变量上有若干进程正在等待，则在对该条件变量执行 signal 操作后，系统调度程序只能在其中选择一个使其恢复运行。

条件变量不是计数器。如果向一个条件变量发送信号，但是在该条件变量上并没有等待进程，则该信号会永远丢失。也就是说，wait 操作必须在 signal 之前。

管程这里的 wait 和 signal 和之前提到的 sleep 和 wakeup 很类似，而后者会存在严重的竞争条件。这是因为当一个进程想睡眠时（还未睡眠）另一个进程试图去唤醒它，从而使得 wakeup 信号丢失。而管程不会发生这种情况。对管程过程的自动互斥保护保证了这一点：如果管程过程中的生产者发现缓冲区满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成而且把生产者标志为不可运行之前，根本不会允许消费者进入管程。

> 条件变量：互斥量负责保证临界区的互斥访问，而条件变量则允许线程（进程）由于一些未达到的条件而阻塞。实际上，绝大多数情况都是两个变量一起使用。关于互斥量、条件变量的关系可以查看 [如何理解互斥锁、条件锁、读写锁以及自旋锁？ - 邱昊宇的回答 - 知乎](https://www.zhihu.com/question/66733477/answer/246535792)。

reference:
[应该如何理解管程？ - 钓雪的回答 - 知乎](https://www.zhihu.com/question/30641734/answer/105402533)


<a id="markdown-17392-管程和信号量的局限性" name="17392-管程和信号量的局限性"></a>
##### 1.7.3.9.2. 管程和信号量的局限性

管程和信号量（包括二元信号量、互斥量）是为了解决公共内存的互斥访问问题的。通过将信号量放入共享内存并用 TSL 或 XCHG 指令保护它们，可以避免竞争。如果一个分布式系统具有多个 CPU，每个 CPU 都有自己的私有内存，它们通过一个局域网连接，那么这些原语将失效。

因此，信号量太低级了，而管程在少数几种编程语言之外又无法使用，并且这些原语均未提供机器间的信息交换方法。


<a id="markdown-17310-消息传递" name="17310-消息传递"></a>
#### 1.7.3.10. 消息传递

**消息传递（message passing）**，使用两条原语进行进程间的通信： send 和 receive，它们像信号量而不像管程，是系统调用而不是语言成分。

由上一小节 [1.7.3.9.2. 管程和信号量的局限性](#17392-管程和信号量的局限性) 中提到的，很容易发现消息传递适用于网络中不同机器的进程通信。这就带来其他很复杂的问题，如消息可能在网络丢失。

消息传递使用形式大致为：
```c++
send(dest, &message);   // 给定目标发送消息

receive(src, &message); // 接收给定源的消息，如果没有消息可用，则接收者可能被堵塞
                        // 或者，带着一个错误码立即返回
```

为了防止消息丢失，发送方和接收方有如下协议（计网知识）：一旦收到信息，接收方返回一条 **ack（acknowledge）** 消息。如果发送方在给定时间内未收到确认信息，则重发消息。具体细节可以参考计网知识。

同时，进程还需解决进程命名的问题，以及性能问题（毕竟网络中进行进程通信比本地通过信号量操作慢的多）。这里先不关心这些问题。


<a id="markdown-173101-消息传递解决生产者-消费者问题" name="173101-消息传递解决生产者-消费者问题"></a>
##### 1.7.3.10.1. 消息传递解决生产者-消费者问题

消息传递解决生产者-消费者问题，区别那些基于共享内存的机制。在下面的代码中，消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并返回一条填充了内容的消息。通过这种方式，系统中总的消息数保持不变，所以消息都可以存放在事先确定数量的内存中。
```c++
// 用 N 条信息实现的生产者-消费者问题
#define N 100               // 缓冲区的槽数目
void producer(void){

    int item;
    message m;              // 消息缓冲区
    while(TRUE){
        item = produce_item();  // 产生放入缓冲区的数据
        receive(consumer,&m);   // 等待消费者发送空缓冲区
        build_message(&m,item); // 建立一个待发送的消息
        send(consumer,&m);      // 发送数据项给消费者
    }

}

void consumer(void){

    int item, i;
    message m;
    for(i = 0; i < N; ++i)  send(producer,&m);  // 发送 N 个空缓冲区
    while(TRUE){
        receive(producer,&m);           // 接收包含数据项的消息
        item = extract_item(&m);        // 提取出来数据项
        send(producer,&m);              // 将空缓冲区发送回生产者
        consumer_item(item);            // 处理数据项
    }

}
```

如果生产者的速度比消费者块，则所有消息最终都被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度块，则情况正好相反：所有消息均为空，等待生产者来填充它们，消费者被阻塞，以等待一条填充过的消息。

消息传递方式可以有许多种变体：

* 为每个进程编址
* 引入**信箱（mailbox）**

> 通常并行程序设计使用消息传递。如 MPI 系统。


<a id="markdown-17311-屏障" name="17311-屏障"></a>
#### 1.7.3.11. 屏障

屏障机制，是一种同步机制，用于进程组而不是用于双进程的生产者-消费者情形。有些应用种划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段。可以通过在每个阶段的结尾安置 **屏障（barrier）**来实现这种行为。当一个进程到达屏障时，它就被屏障阻拦，直到所有进程都到达该屏障为止。

屏障的工作机制：如有四个进程接近屏障。过一会，第一个进程完成了第一阶段的计算工作。它接着执行 **barrier** 原语，这通常是调用一个库过程。于是该进程被挂起。一会儿，第二个第三个进程也完成了第一阶段的计算工作，也跟着执行 barrier 原语。当最后一个进程到达屏障时，所有的进程被释放。
